# InvestAi

AplicaÃ§Ã£o criada com o intuito de buscar, analisar e prever informaÃ§Ãµes sobre a bolsa de valores, indicando boas aÃ§Ãµes para compra e venda.

## ğŸ“Œ Funcionalidades

- **Coleta de Dados**: Utiliza Web Scraping na plataforma [Status Invest](https://statusinvest.com.br/) para capturar informaÃ§Ãµes relevantes sobre ativos da B3.
- **Armazenamento**: Os dados coletados sÃ£o salvos em um banco **PostgreSQL**.
- **Monitoramento ContÃ­nuo**: Um agendador executa a coleta a cada 4 horas automaticamente.
- **Modelo de PrevisÃ£o**: Utiliza **Redes Neurais LSTM** para prever os preÃ§os futuros das aÃ§Ãµes com base nos dados coletados.
- **VisualizaÃ§Ã£o**: Os resultados sÃ£o apresentados em grÃ¡ficos para facilitar a anÃ¡lise.

## ğŸ“‚ Estrutura do Projeto
```
src/
â”‚â”€â”€ api/                   # ImplementaÃ§Ã£o de APIs futuras
â”‚â”€â”€ collectors/            # Scripts de coleta de dados
â”‚   â”‚â”€â”€ data_collector.py  # Web Scraper para Status Invest
â”‚   â”‚â”€â”€ selenium_scraper.py # Alternativa usando Selenium
â”‚â”€â”€ models/                # Modelos de Machine Learning
â”‚   â”‚â”€â”€ predictor_lstm.py  # ImplementaÃ§Ã£o do modelo LSTM
â”‚â”€â”€ preprocessing/         # PrÃ©-processamento de dados
â”‚â”€â”€ scheduler/             # Agendador de tarefas
â”‚   â”‚â”€â”€ scheduler_collect.py # Executa a coleta automaticamente
â”‚â”€â”€ requirements.txt       # DependÃªncias do projeto
â”‚â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
```

## âš™ï¸ Tecnologias Utilizadas
- **Python** (Linguagem principal)
- **BeautifulSoup** (Web Scraping)
- **Selenium** (Alternativa para scraping dinÃ¢mico)
- **PostgreSQL** (Banco de dados relacional)
- **MongoDB** (Armazenamento de logs)
- **TensorFlow/Keras** (Modelo LSTM para previsÃ£o)
- **Pandas & NumPy** (ManipulaÃ§Ã£o de dados)
- **Matplotlib** (VisualizaÃ§Ã£o dos dados)

## ğŸš€ Como Rodar o Projeto

### ğŸ”§ InstalaÃ§Ã£o das DependÃªncias

```bash
pip install -r requirements.txt
```

### ğŸ“Š Executar a Coleta de Dados

```bash
python src/collectors/data_collector.py
```

### â³ Agendar a Coleta AutomÃ¡tica

```bash
python src/scheduler/scheduler_collect.py
```

### ğŸ“ˆ Treinar o Modelo de PrevisÃ£o

```bash
python src/models/predictor_lstm.py
```

## ğŸŒ Deploy na Nuvem
Para manter a aplicaÃ§Ã£o rodando continuamente, recomendamos o uso do **Railway** ou **Render**. Veja os passos detalhados na documentaÃ§Ã£o.

## ğŸ“Œ PrÃ³ximos Passos
- ğŸ”„ Melhorar a precisÃ£o do modelo de previsÃ£o adicionando novos indicadores financeiros.
- ğŸ“ˆ Criar um frontend para visualizar as previsÃµes diretamente.
- â˜ï¸ Publicar a aplicaÃ§Ã£o na nuvem para rodar de forma automÃ¡tica.

---

**Criado por Rafael Baltar** ğŸš€

